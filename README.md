# Суть задачи

&ensp; &ensp; Задача кредитного скоринга - одна из наиболее популярных областей, где применяются алгоритмы машинного обучения. 
Качественная скоринговая модель позволяет ставить принятие решения на поток, сокращать сроки выдачи и упрощать сбор необходимых документов. Для клиента банка применение скоринга снижает стоимость выдачи и самого кредита, значительно сокращает перечень запрашиваемых банком документов и сроки выдачи.
В работе решается задача построения наиболее точной классификационной модели, предсказывающей вероятность возврата кредита (`development.ipynb`), после чего происходит валидация разработанных моделей (`validation.ipynb`).

# Используемые данные

&ensp; &ensp; Данные, которые используются для решения данной задачи, представлены в папке `srm23-spring-bank-scoring-case`: `X_train`, `X_test`,
`y_train`, `y_test_sample`. В `X_train` и `X_test` размещены данные 10 признаков, по которым предлагается осуществлять предсказание дефолта клиента, 
В файле `y_train` находятся ответы, была или нет просрочка (1 - дефолт, 0 - не дефолт) по факту, а в `y_test_sample` находятся рандомные вероятности того, была просрочка или нет.

# Стек технологий

`Python`, `Numpy`, `Pandas`, `Matplotlib`, `Scikit-learn`, `Seaborn`, 
`SciPy`, `Statsmodels`, `LGBM`, `CatBoost`, `XGBoost`, `TensorFlow`, `Keras`, `SciKeras`, `Imblearn`, `HyperOpt`, `Shap`


# Метрики и оценка качества моделей

&ensp; &ensp; В качестве основной метрики рассматривается ROC_AUC (Area Under ROC Curve), однако отслеживаются и другие показатели: accuracy, precision, recall, f-мера. Более того, в разделе валидации, проводятся различные статистические тесты факторов и моделей (эффективность ранжирования модели и факторов, 2.5 перцентиль бутстрэп-распределения Джини по модели и факторам, оценка Information Value, тесты Колмогорова-Смирнова, анализ PSI по факторам и т.д.).

# Используемые алгоритмы

&ensp; &ensp; Применяются как "простые" алгоритмы: линейная и логистическая регрессии, KNN, SGD Classifier, Decision Tree, так и ансамбли моделей: из бэггингов рассматривается только Random Forest, однако среди бустинговых моделей применяются сразу несколько: LGBMClassifier, CatBoostClassifier, XGBClassifier и GradientBoostingClassifier. Рассматривается также эффективность применения полносвязной нейронной сети. В заключение осуществляется блендинг лучших моделей. 

# Результаты

&ensp; &ensp; В ходе данного исследования лучших значений roc_auc удалось добиться при использовании блендинговых моделей, из которых особо выделяются 2 модели: CatBoostClassifier (roc_auc = 0.8648 +/- 0.0055) и LGBMClassifier (roc_auc = 0.8642 +/- 0.0056),  а также после блендинга этих двух моделей в соотношении (90% на 10%): roc_auc = 0.8653 +/- 0.0055 (private_score на Kaggle 0.87158).

CatBoost-модель имеет более высокий precision (около 60%), но менее низкий recall (20%), что означает, что она более консервативна в определении дефолтных клиентов. То есть, она склонна относить к классу 1 только тех клиентов, которые она считает наиболее вероятными дефолтниками. Но, т.к. у нее низкий recall, то она пропускает много дефолтных клиентов, которые на самом деле являются дефолтниками, но были отнесены к классу 0.

LGBM-модель же наоборот, получилась агрессивной моделью: имеет более высокий recall (почти 80%), но низкий precision (чуть более 20%).

Однако нужно в первую очередь понять, что для нас важнее: выдать больше кредитов, при этом "отсеивать" наиболее вероятных дефолтников или же тщательно разбирать заявки и работать с теми клиентами, у кого наиболее чистая кредитная история (т.е. когда цена ошибки высока). Если же хотим добиться "золотой середины", то тогда рекомендуется использовать блендинг CatBoost + LGBM.